import os
import subprocess
import pandas as pd
from datetime import datetime
import requests
import re
import argparse

def print_status(msg, status="info"):
    icons = {"info": "‚ÑπÔ∏è", "success": "‚úÖ", "warning": "‚ö†Ô∏è", "error": "‚ùå", "progress": "üîÑ"}
    print(f"{datetime.now().strftime('%H:%M:%S')} {icons.get(status, '')} {msg}")

parser = argparse.ArgumentParser(description="Generate educational stories from news or prompts.")
parser.add_argument("--csv", type=str, help="Path to input CSV", default=os.getenv("CSV_PATH", "data/input.csv"))
parser.add_argument("--news_limit", type=int, help="Number of news items to fetch", default=10)
parser.add_argument("--regions", type=str, help="Comma-separated list of country codes (e.g., 'us,in')", default="in")
parser.add_argument("--query", type=str, help="Search query for GNews", default=None)
args = parser.parse_args()

CSV_PATH = args.csv
NEWS_LIMIT = args.news_limit
REGIONS = [r.strip() for r in args.regions.split(",") if r.strip()]
QUERY = args.query

STORY_DIR = "stories/generated"
MODEL_NAME = "gemma"

try:
    with open("gnews_api.txt", "r") as f:
        GNEWS_API_KEY = f.read().strip()
except Exception as e:
    print_status(f"‚ùå Failed to read GNews API key: {e}", "error")
    GNEWS_API_KEY = ""

GNEWS_ENDPOINT = "https://gnews.io/api/v4/search"
os.makedirs(STORY_DIR, exist_ok=True)

def fetch_news(country):
    if not QUERY:
        print_status("‚ö†Ô∏è QUERY is not set. Skipping news fetch.", "warning")
        return []
    url = f"{GNEWS_ENDPOINT}?q={QUERY}&lang=hi&country={country}&max={NEWS_LIMIT}&apikey={GNEWS_API_KEY}"
    print_status(f"üîç Fetching news for region '{country}' via URL: {url}", "progress")
    try:
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
        return [
            {
                "title": article.get("title", ""),
                "description": article.get("description", ""),
                "image": article.get("image", ""),
                "url": article.get("url", "")
            } for article in data.get("articles", []) if article.get("title")
        ]
    except Exception as e:
        print_status(f"Failed to fetch news for {country}: {e}", "error")
        return []

def clean_story(text):
    text = re.sub(r'[\U00010000-\U0010ffff]', '', text, flags=re.UNICODE)
    text = re.sub(r'#\w+', '', text)
    text = re.sub(r'[\[\(].*?[\]\)]', '', text)
    text = re.sub(r'^(title|script|heading)[:\-‚Äì]\s*', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\n{2,}', '\n', text)
    text = re.sub(r' +', ' ', text)
    return '\n'.join(line.strip() for line in text.splitlines()).strip()

def generate_story(prompt):
    system_prompt = (
        "‡§Ü‡§™ ‡§è‡§ï ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§§‡§æ ‡§π‡•à‡§Ç ‡§ú‡•ã YouTube Shorts ‡§ï‡•á ‡§≤‡§ø‡§è ‡§õ‡•ã‡§ü‡•á, ‡§∂‡•à‡§ï‡•ç‡§∑‡§ø‡§ï ‡§î‡§∞ ‡§Ü‡§ï‡§∞‡•ç‡§∑‡§ï ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§≤‡§ø‡§ñ‡§§‡•á ‡§π‡•à‡§Ç‡•§\n"
        "‡§Ü‡§™‡§ï‡§æ ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø ‡§∏‡§Æ‡§æ‡§ö‡§æ‡§∞ ‡§µ‡§ø‡§∑‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§î‡§∞ ‡§è‡§≤‡•ç‡§ó‡•ã‡§∞‡§ø‡§¶‡§Æ ‡§§‡§ï ‡§™‡§π‡•Å‡§Ç‡§ö ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§µ‡§æ ‡§¶‡•á‡§®‡•á ‡§ï‡•á ‡§§‡§∞‡•Ä‡§ï‡•á ‡§∏‡•á ‡§∏‡§Æ‡§ù‡§æ‡§®‡§æ ‡§π‡•à‡•§\n"
        "‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§ø‡§è ‡§ó‡§è ‡§π‡•á‡§°‡§≤‡§æ‡§á‡§® ‡§î‡§∞ ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á:\n"
        "- ‡§∏‡§Æ‡§æ‡§ö‡§æ‡§∞ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à ‡§Ø‡§π ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§ï‡§∞‡•á‡§Ç\n"
        "- ‡§á‡§∏‡§ï‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§Ö‡§∞‡•ç‡§• ‡§π‡•à ‡§Ø‡§æ ‡§Ø‡§π ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•à, ‡§Ø‡§π ‡§¨‡§§‡§æ‡§è‡§Ç\n"
        "- ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü ‡§ï‡•á ‡§Ö‡§Ç‡§§ ‡§Æ‡•á‡§Ç CTA ‡§ú‡•ã‡§°‡§º‡•á‡§Ç: '‡§≤‡§æ‡§á‡§ï ‡§ï‡§∞‡•á‡§Ç, ‡§∂‡•á‡§Ø‡§∞ ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§∏‡§¨‡•ç‡§∏‡§ï‡•ç‡§∞‡§æ‡§á‡§¨ ‡§ï‡§∞‡•á‡§Ç!'\n\n"
        "‡§®‡§ø‡§Ø‡§Æ:\n"
        "- ‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§ü 200 ‡§∂‡§¨‡•ç‡§¶‡•ã‡§Ç ‡§∏‡•á ‡§ï‡§Æ ‡§π‡•ã‡§®‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è\n"
        "- ‡§á‡§∏‡•á ‡§®‡•á‡§ö‡•Å‡§∞‡§≤ ‡§§‡§∞‡•Ä‡§ï‡•á ‡§∏‡•á ‡§≤‡§ø‡§ñ‡•á‡§Ç ‡§ú‡§ø‡§∏‡§∏‡•á ‡§µ‡•â‡§Ø‡§∏‡§ì‡§µ‡§∞ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§≤‡§ó‡•á\n"
        "- ‡§ï‡•ã‡§à ‡§π‡•à‡§∂‡§ü‡•à‡§ó, ‡§á‡§Æ‡•ã‡§ú‡•Ä ‡§Ø‡§æ ‡§µ‡§∞‡•ç‡§£‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§≤‡•á‡§¨‡§≤ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§® ‡§ï‡§∞‡•á‡§Ç\n"
        "- ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§Æ‡•á‡§Ç ‡§ï‡•á‡§µ‡§≤ ‡§¨‡•ã‡§≤‡§ö‡§æ‡§≤ ‡§ï‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§π‡•ã‡§®‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è, ‡§∂‡•Ä‡§∞‡•ç‡§∑‡§ï ‡§Ø‡§æ ‡§π‡•á‡§°‡§ø‡§Ç‡§ó ‡§®‡§π‡•Ä‡§Ç\n"
    )

    try:
        result = subprocess.run(
            ['ollama', 'run', MODEL_NAME],
            input=f"<|system|>\n{system_prompt}\n<|user|>\n{prompt}",
            text=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            encoding='utf-8',
            timeout=120,
            errors="replace",
        )
        if result.returncode != 0:
            raise Exception(result.stderr.strip())
        return result.stdout.strip()
    except Exception as e:
        raise Exception(f"Model generation error: {e}")

def process_news():
    print_status("üöÄ Starting content generation from GNews", "progress")
    try:
        df = pd.read_csv(CSV_PATH, encoding="utf-8")
    except Exception:
        df = pd.DataFrame(columns=["ID", "Prompt", "ImageURL", "StoryText", "StoryStatus"])

    for region in REGIONS:
        for article in fetch_news(region):
            prompt = f"{article['title']}\n\n{article['description']}"
            image = article.get("image", "")
            story_id = df["ID"].max() + 1 if not df.empty else 1
            df = pd.concat([
                df,
                pd.DataFrame([{ "ID": story_id, "Prompt": prompt, "ImageURL": image, "StoryText": "", "StoryStatus": "", "NewsUrl": article["url"] }])
            ], ignore_index=True)

    for idx, row in df.iterrows():
        if str(row.get("StoryStatus", "")).lower() == "completed":
            continue

        prompt = str(row.get("Prompt", "")).strip()
        if not prompt:
            continue

        story_id = row.get("ID", idx)
        try:
            story = generate_story(prompt)
            cleaned = clean_story(story)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"story_{story_id}_{timestamp}.txt"
            story_path = os.path.join(STORY_DIR, filename)
            with open(story_path, 'w', encoding='utf-8') as f:
                f.write(cleaned)

            df.at[idx, "StoryText"] = cleaned
            df.at[idx, "StoryStatus"] = "Completed"
            df.at[idx, "StoryPath"] = story_path
            print_status(f"‚úÖ Story {story_id} generated and saved", "success")
        except Exception as e:
            df.at[idx, "StoryStatus"] = f"Failed: {str(e)}"
            print_status(f"‚ùå Failed to generate story {story_id}: {e}", "error")

    try:
        df.to_csv(CSV_PATH, index=False)
        print_status("‚úÖ CSV updated with new entries", "success")
    except Exception as e:
        print_status(f"‚ùå Failed to save CSV: {e}", "error")

if __name__ == "__main__":
    process_news()
    print_status("üåü All news processed.", "success")
